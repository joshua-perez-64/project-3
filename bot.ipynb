{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253676</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253677</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253678</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253679</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253680 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0                   0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1                   0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2                   0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3                   0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4                   0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "...                 ...     ...       ...        ...   ...     ...     ...   \n",
       "253675              0.0     1.0       1.0        1.0  45.0     0.0     0.0   \n",
       "253676              1.0     1.0       1.0        1.0  18.0     0.0     0.0   \n",
       "253677              0.0     0.0       0.0        1.0  28.0     0.0     0.0   \n",
       "253678              0.0     1.0       0.0        1.0  23.0     0.0     0.0   \n",
       "253679              1.0     1.0       1.0        1.0  25.0     0.0     0.0   \n",
       "\n",
       "        HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  \\\n",
       "0                        0.0           0.0     0.0      1.0   \n",
       "1                        0.0           1.0     0.0      0.0   \n",
       "2                        0.0           0.0     1.0      0.0   \n",
       "3                        0.0           1.0     1.0      1.0   \n",
       "4                        0.0           1.0     1.0      1.0   \n",
       "...                      ...           ...     ...      ...   \n",
       "253675                   0.0           0.0     1.0      1.0   \n",
       "253676                   0.0           0.0     0.0      0.0   \n",
       "253677                   0.0           1.0     1.0      0.0   \n",
       "253678                   0.0           0.0     1.0      1.0   \n",
       "253679                   1.0           1.0     1.0      0.0   \n",
       "\n",
       "        HvyAlcoholConsump  AnyHealthcare  NoDocbcCost  GenHlth  MentHlth  \\\n",
       "0                     0.0            1.0          0.0      5.0      18.0   \n",
       "1                     0.0            0.0          1.0      3.0       0.0   \n",
       "2                     0.0            1.0          1.0      5.0      30.0   \n",
       "3                     0.0            1.0          0.0      2.0       0.0   \n",
       "4                     0.0            1.0          0.0      2.0       3.0   \n",
       "...                   ...            ...          ...      ...       ...   \n",
       "253675                0.0            1.0          0.0      3.0       0.0   \n",
       "253676                0.0            1.0          0.0      4.0       0.0   \n",
       "253677                0.0            1.0          0.0      1.0       0.0   \n",
       "253678                0.0            1.0          0.0      3.0       0.0   \n",
       "253679                0.0            1.0          0.0      2.0       0.0   \n",
       "\n",
       "        PhysHlth  DiffWalk  Sex   Age  Education  Income  \n",
       "0           15.0       1.0  0.0   9.0        4.0     3.0  \n",
       "1            0.0       0.0  0.0   7.0        6.0     1.0  \n",
       "2           30.0       1.0  0.0   9.0        4.0     8.0  \n",
       "3            0.0       0.0  0.0  11.0        3.0     6.0  \n",
       "4            0.0       0.0  0.0  11.0        5.0     4.0  \n",
       "...          ...       ...  ...   ...        ...     ...  \n",
       "253675       5.0       0.0  1.0   5.0        6.0     7.0  \n",
       "253676       0.0       1.0  0.0  11.0        2.0     4.0  \n",
       "253677       0.0       0.0  0.0   2.0        5.0     2.0  \n",
       "253678       0.0       0.0  1.0   7.0        5.0     1.0  \n",
       "253679       0.0       0.0  0.0   9.0        6.0     2.0  \n",
       "\n",
       "[253680 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import dependencies and read in data\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as ps\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import display\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "import pydotplus\n",
    "import os\n",
    "from IPython.display import Image\n",
    "from transformers import pipeline\n",
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "df = pd.read_csv(\"resources/diabetes_df.csv\")\n",
    "pd.options.display.max_columns = None\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253680 entries, 0 to 253679\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Diabetes_binary       253680 non-null  float64\n",
      " 1   HighBP                253680 non-null  float64\n",
      " 2   HighChol              253680 non-null  float64\n",
      " 3   CholCheck             253680 non-null  float64\n",
      " 4   BMI                   253680 non-null  float64\n",
      " 5   Smoker                253680 non-null  float64\n",
      " 6   Stroke                253680 non-null  float64\n",
      " 7   HeartDiseaseorAttack  253680 non-null  float64\n",
      " 8   PhysActivity          253680 non-null  float64\n",
      " 9   Fruits                253680 non-null  float64\n",
      " 10  Veggies               253680 non-null  float64\n",
      " 11  HvyAlcoholConsump     253680 non-null  float64\n",
      " 12  AnyHealthcare         253680 non-null  float64\n",
      " 13  NoDocbcCost           253680 non-null  float64\n",
      " 14  GenHlth               253680 non-null  float64\n",
      " 15  MentHlth              253680 non-null  float64\n",
      " 16  PhysHlth              253680 non-null  float64\n",
      " 17  DiffWalk              253680 non-null  float64\n",
      " 18  Sex                   253680 non-null  float64\n",
      " 19  Age                   253680 non-null  float64\n",
      " 20  Education             253680 non-null  float64\n",
      " 21  Income                253680 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 42.6 MB\n"
     ]
    }
   ],
   "source": [
    "#checking Dtypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0              0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1              0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2              0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3              0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4              0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  HvyAlcoholConsump  \\\n",
       "0                   0.0           0.0     0.0      1.0                0.0   \n",
       "1                   0.0           1.0     0.0      0.0                0.0   \n",
       "2                   0.0           0.0     1.0      0.0                0.0   \n",
       "3                   0.0           1.0     1.0      1.0                0.0   \n",
       "4                   0.0           1.0     1.0      1.0                0.0   \n",
       "\n",
       "   AnyHealthcare  NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex  \\\n",
       "0            1.0          0.0      5.0      18.0      15.0       1.0  0.0   \n",
       "1            0.0          1.0      3.0       0.0       0.0       0.0  0.0   \n",
       "2            1.0          1.0      5.0      30.0      30.0       1.0  0.0   \n",
       "3            1.0          0.0      2.0       0.0       0.0       0.0  0.0   \n",
       "4            1.0          0.0      2.0       3.0       0.0       0.0  0.0   \n",
       "\n",
       "    Age  Education  Income  \n",
       "0   9.0        4.0     3.0  \n",
       "1   7.0        6.0     1.0  \n",
       "2   9.0        4.0     8.0  \n",
       "3  11.0        3.0     6.0  \n",
       "4  11.0        5.0     4.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0              0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1              0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2              0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3              0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4              0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  HvyAlcoholConsump  \\\n",
       "0                   0.0           0.0     0.0      1.0                0.0   \n",
       "1                   0.0           1.0     0.0      0.0                0.0   \n",
       "2                   0.0           0.0     1.0      0.0                0.0   \n",
       "3                   0.0           1.0     1.0      1.0                0.0   \n",
       "4                   0.0           1.0     1.0      1.0                0.0   \n",
       "\n",
       "   GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \n",
       "0      5.0      18.0      15.0       1.0  0.0   9.0        4.0  \n",
       "1      3.0       0.0       0.0       0.0  0.0   7.0        6.0  \n",
       "2      5.0      30.0      30.0       1.0  0.0   9.0        4.0  \n",
       "3      2.0       0.0       0.0       0.0  0.0  11.0        3.0  \n",
       "4      2.0       3.0       0.0       0.0  0.0  11.0        5.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort dataframe for diabetes_binary, highbp, highchol, cholcheck, bmi, smoker, stroke, heart deseaseor attack, physactivity, fruits, veggies, hvyalcoholcunsump, genhealth, menthealth, physhealth, diffwalk, sex, education\n",
    "diabetes_df = df[['Diabetes_binary', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education']]\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_binary\n",
       "0.0    218334\n",
       "1.0     35346\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0= no\n",
    "#1= yes\n",
    "diabetes_df['Diabetes_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Histogram of Age\n",
    "sns.boxplot(diabetes_df['Age'])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_binary         0\n",
       "HighBP                  0\n",
       "HighChol                0\n",
       "CholCheck               0\n",
       "BMI                     0\n",
       "Smoker                  0\n",
       "Stroke                  0\n",
       "HeartDiseaseorAttack    0\n",
       "PhysActivity            0\n",
       "Fruits                  0\n",
       "Veggies                 0\n",
       "HvyAlcoholConsump       0\n",
       "GenHlth                 0\n",
       "MentHlth                0\n",
       "PhysHlth                0\n",
       "DiffWalk                0\n",
       "Sex                     0\n",
       "Age                     0\n",
       "Education               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count null values\n",
    "diabetes_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tz/nqby0pvn6llfbd7c3rtk0k280000gn/T/ipykernel_66003/4193381810.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diabetes_df['BMI'] = pd.DataFrame(scaler.fit_transform(diabetes_df[['BMI']]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253676</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253677</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253678</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253679</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253680 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Diabetes_binary  HighBP  HighChol  CholCheck       BMI  Smoker  \\\n",
       "0                   0.0     1.0       1.0        1.0  1.857143     1.0   \n",
       "1                   0.0     0.0       0.0        0.0 -0.285714     1.0   \n",
       "2                   0.0     1.0       1.0        1.0  0.142857     0.0   \n",
       "3                   0.0     1.0       0.0        1.0  0.000000     0.0   \n",
       "4                   0.0     1.0       1.0        1.0 -0.428571     0.0   \n",
       "...                 ...     ...       ...        ...       ...     ...   \n",
       "253675              0.0     1.0       1.0        1.0  2.571429     0.0   \n",
       "253676              1.0     1.0       1.0        1.0 -1.285714     0.0   \n",
       "253677              0.0     0.0       0.0        1.0  0.142857     0.0   \n",
       "253678              0.0     1.0       0.0        1.0 -0.571429     0.0   \n",
       "253679              1.0     1.0       1.0        1.0 -0.285714     0.0   \n",
       "\n",
       "        Stroke  HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  \\\n",
       "0          0.0                   0.0           0.0     0.0      1.0   \n",
       "1          0.0                   0.0           1.0     0.0      0.0   \n",
       "2          0.0                   0.0           0.0     1.0      0.0   \n",
       "3          0.0                   0.0           1.0     1.0      1.0   \n",
       "4          0.0                   0.0           1.0     1.0      1.0   \n",
       "...        ...                   ...           ...     ...      ...   \n",
       "253675     0.0                   0.0           0.0     1.0      1.0   \n",
       "253676     0.0                   0.0           0.0     0.0      0.0   \n",
       "253677     0.0                   0.0           1.0     1.0      0.0   \n",
       "253678     0.0                   0.0           0.0     1.0      1.0   \n",
       "253679     0.0                   1.0           1.0     1.0      0.0   \n",
       "\n",
       "        HvyAlcoholConsump  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  \\\n",
       "0                     0.0      5.0      18.0      15.0       1.0  0.0   9.0   \n",
       "1                     0.0      3.0       0.0       0.0       0.0  0.0   7.0   \n",
       "2                     0.0      5.0      30.0      30.0       1.0  0.0   9.0   \n",
       "3                     0.0      2.0       0.0       0.0       0.0  0.0  11.0   \n",
       "4                     0.0      2.0       3.0       0.0       0.0  0.0  11.0   \n",
       "...                   ...      ...       ...       ...       ...  ...   ...   \n",
       "253675                0.0      3.0       0.0       5.0       0.0  1.0   5.0   \n",
       "253676                0.0      4.0       0.0       0.0       1.0  0.0  11.0   \n",
       "253677                0.0      1.0       0.0       0.0       0.0  0.0   2.0   \n",
       "253678                0.0      3.0       0.0       0.0       0.0  1.0   7.0   \n",
       "253679                0.0      2.0       0.0       0.0       0.0  0.0   9.0   \n",
       "\n",
       "        Education  \n",
       "0             4.0  \n",
       "1             6.0  \n",
       "2             4.0  \n",
       "3             3.0  \n",
       "4             5.0  \n",
       "...           ...  \n",
       "253675        6.0  \n",
       "253676        2.0  \n",
       "253677        5.0  \n",
       "253678        5.0  \n",
       "253679        6.0  \n",
       "\n",
       "[253680 rows x 19 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = RobustScaler()\n",
    "diabetes_df['BMI'] = pd.DataFrame(scaler.fit_transform(diabetes_df[['BMI']]))\n",
    "diabetes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing sets\n",
    "# Create the features DataFrame, X\n",
    "X = diabetes_df.copy()\n",
    "X = X.drop(columns='Diabetes_binary')\n",
    "\n",
    "# Create the target DataFrame, y\n",
    "y = diabetes_df['Diabetes_binary']\n",
    "\n",
    "# Use train_test_split to separate the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an undersampler\n",
    "rus = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the data to create a balanced dataset\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled class distribution: Counter({0.0: 26562, 1.0: 26562})\n"
     ]
    }
   ],
   "source": [
    "# Check the class distribution after undersampling\n",
    "print(f\"Resampled class distribution: {Counter(y_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a `LogisticRegression` function and assign it \n",
    "# to a variable named `logistic_regression_model`.\n",
    "logistic_regression_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "logistic_regression_model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7279091769157995"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the fitted model to the `test` dataset\n",
    "testing_predictions = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Save both the test predictions and actual test values to a DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    \"Testing Data Predictions\": testing_predictions, \n",
    "    \"Testing Data Actual Targets\": y_test})\n",
    "\n",
    "# Calculate the model's accuracy on the test dataset\n",
    "accuracy_score(y_test, testing_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7279091769157995"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the fitted model to the `test` dataset\n",
    "testing_predictions = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Save both the test predictions and actual test values to a DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    \"Testing Data Predictions\": testing_predictions, \n",
    "    \"Testing Data Actual Targets\": y_test})\n",
    "\n",
    "# Calculate the model's accuracy on the test dataset\n",
    "accuracy_score(y_test, testing_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6772  2012]\n",
      " [15244 39392]]\n"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "print(confusion_matrix(y_test,testing_predictions, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.77      0.44      8784\n",
      "           0       0.95      0.72      0.82     54636\n",
      "\n",
      "    accuracy                           0.73     63420\n",
      "   macro avg       0.63      0.75      0.63     63420\n",
      "weighted avg       0.86      0.73      0.77     63420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a classification report\n",
    "print(classification_report(y_test, testing_predictions, labels = [1, 0]))\n",
    "#logistics regression utilizing robust scaler on BMI higher recall focuses on finding false negitives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled class distribution: Counter({0.0: 28349, 1.0: 28349})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tz/nqby0pvn6llfbd7c3rtk0k280000gn/T/ipykernel_66003/1452167375.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diabetes_df['BMI'] = scaler.fit_transform(diabetes_df[['BMI']])\n"
     ]
    }
   ],
   "source": [
    "#ATTEMPT TO CODE NUERAL NETWORK\n",
    "\n",
    "# Scale BMI\n",
    "scaler = RobustScaler()\n",
    "diabetes_df['BMI'] = scaler.fit_transform(diabetes_df[['BMI']])\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = diabetes_df.drop(columns='Diabetes_binary')\n",
    "y = diabetes_df['Diabetes_binary']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Undersample to create a balanced dataset\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class distribution after undersampling\n",
    "print(f\"Resampled class distribution: {Counter(y_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer and first hidden layer with 16 neurons\n",
    "model.add(Dense(16, input_shape=(X_resampled.shape[1],), activation='relu'))\n",
    "\n",
    "# Add another hidden layer\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Output layer (since this is binary classification, use sigmoid activation)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 470us/step - accuracy: 0.6553 - loss: 0.6360 - val_accuracy: 0.7338 - val_loss: 0.5079\n",
      "Epoch 2/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 418us/step - accuracy: 0.7394 - loss: 0.5243 - val_accuracy: 0.6907 - val_loss: 0.5585\n",
      "Epoch 3/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 400us/step - accuracy: 0.7435 - loss: 0.5170 - val_accuracy: 0.7169 - val_loss: 0.5211\n",
      "Epoch 4/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396us/step - accuracy: 0.7424 - loss: 0.5167 - val_accuracy: 0.7006 - val_loss: 0.5530\n",
      "Epoch 5/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 405us/step - accuracy: 0.7454 - loss: 0.5137 - val_accuracy: 0.7007 - val_loss: 0.5406\n",
      "Epoch 6/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 401us/step - accuracy: 0.7461 - loss: 0.5117 - val_accuracy: 0.7080 - val_loss: 0.5264\n",
      "Epoch 7/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 403us/step - accuracy: 0.7454 - loss: 0.5111 - val_accuracy: 0.7086 - val_loss: 0.5233\n",
      "Epoch 8/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434us/step - accuracy: 0.7457 - loss: 0.5132 - val_accuracy: 0.7141 - val_loss: 0.5223\n",
      "Epoch 9/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 398us/step - accuracy: 0.7488 - loss: 0.5074 - val_accuracy: 0.7188 - val_loss: 0.5183\n",
      "Epoch 10/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 399us/step - accuracy: 0.7502 - loss: 0.5056 - val_accuracy: 0.6579 - val_loss: 0.6008\n",
      "Epoch 11/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 403us/step - accuracy: 0.7462 - loss: 0.5120 - val_accuracy: 0.7111 - val_loss: 0.5267\n",
      "Epoch 12/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 406us/step - accuracy: 0.7459 - loss: 0.5106 - val_accuracy: 0.7371 - val_loss: 0.4894\n",
      "Epoch 13/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429us/step - accuracy: 0.7489 - loss: 0.5070 - val_accuracy: 0.7297 - val_loss: 0.5066\n",
      "Epoch 14/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410us/step - accuracy: 0.7475 - loss: 0.5095 - val_accuracy: 0.6873 - val_loss: 0.5540\n",
      "Epoch 15/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423us/step - accuracy: 0.7486 - loss: 0.5076 - val_accuracy: 0.7072 - val_loss: 0.5249\n",
      "Epoch 16/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 406us/step - accuracy: 0.7490 - loss: 0.5078 - val_accuracy: 0.7234 - val_loss: 0.5087\n",
      "Epoch 17/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396us/step - accuracy: 0.7500 - loss: 0.5065 - val_accuracy: 0.7025 - val_loss: 0.5283\n",
      "Epoch 18/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 399us/step - accuracy: 0.7477 - loss: 0.5089 - val_accuracy: 0.7009 - val_loss: 0.5433\n",
      "Epoch 19/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 394us/step - accuracy: 0.7453 - loss: 0.5099 - val_accuracy: 0.7257 - val_loss: 0.5069\n",
      "Epoch 20/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 393us/step - accuracy: 0.7492 - loss: 0.5078 - val_accuracy: 0.7142 - val_loss: 0.5166\n",
      "Epoch 21/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 402us/step - accuracy: 0.7512 - loss: 0.5039 - val_accuracy: 0.7134 - val_loss: 0.5133\n",
      "Epoch 22/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397us/step - accuracy: 0.7499 - loss: 0.5088 - val_accuracy: 0.7176 - val_loss: 0.5150\n",
      "Epoch 23/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 393us/step - accuracy: 0.7459 - loss: 0.5081 - val_accuracy: 0.6938 - val_loss: 0.5564\n",
      "Epoch 24/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391us/step - accuracy: 0.7495 - loss: 0.5066 - val_accuracy: 0.6882 - val_loss: 0.5532\n",
      "Epoch 25/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 394us/step - accuracy: 0.7548 - loss: 0.5021 - val_accuracy: 0.6787 - val_loss: 0.5694\n",
      "Epoch 26/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 402us/step - accuracy: 0.7463 - loss: 0.5089 - val_accuracy: 0.7181 - val_loss: 0.5084\n",
      "Epoch 27/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 394us/step - accuracy: 0.7499 - loss: 0.5049 - val_accuracy: 0.6672 - val_loss: 0.5863\n",
      "Epoch 28/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 393us/step - accuracy: 0.7516 - loss: 0.5041 - val_accuracy: 0.7176 - val_loss: 0.5111\n",
      "Epoch 29/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 394us/step - accuracy: 0.7498 - loss: 0.5065 - val_accuracy: 0.7017 - val_loss: 0.5413\n",
      "Epoch 30/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 395us/step - accuracy: 0.7508 - loss: 0.5023 - val_accuracy: 0.7167 - val_loss: 0.5102\n",
      "Epoch 31/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 390us/step - accuracy: 0.7526 - loss: 0.5021 - val_accuracy: 0.7095 - val_loss: 0.5303\n",
      "Epoch 32/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397us/step - accuracy: 0.7510 - loss: 0.5024 - val_accuracy: 0.7098 - val_loss: 0.5296\n",
      "Epoch 33/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391us/step - accuracy: 0.7483 - loss: 0.5061 - val_accuracy: 0.6950 - val_loss: 0.5516\n",
      "Epoch 34/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 394us/step - accuracy: 0.7487 - loss: 0.5066 - val_accuracy: 0.7171 - val_loss: 0.5193\n",
      "Epoch 35/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391us/step - accuracy: 0.7523 - loss: 0.5013 - val_accuracy: 0.7135 - val_loss: 0.5162\n",
      "Epoch 36/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 390us/step - accuracy: 0.7508 - loss: 0.5051 - val_accuracy: 0.7175 - val_loss: 0.5154\n",
      "Epoch 37/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 400us/step - accuracy: 0.7517 - loss: 0.5059 - val_accuracy: 0.7062 - val_loss: 0.5356\n",
      "Epoch 38/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 394us/step - accuracy: 0.7495 - loss: 0.5053 - val_accuracy: 0.7344 - val_loss: 0.4925\n",
      "Epoch 39/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391us/step - accuracy: 0.7510 - loss: 0.5038 - val_accuracy: 0.7390 - val_loss: 0.4805\n",
      "Epoch 40/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 393us/step - accuracy: 0.7522 - loss: 0.5036 - val_accuracy: 0.7076 - val_loss: 0.5239\n",
      "Epoch 41/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 392us/step - accuracy: 0.7500 - loss: 0.5061 - val_accuracy: 0.6839 - val_loss: 0.5663\n",
      "Epoch 42/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 401us/step - accuracy: 0.7531 - loss: 0.5028 - val_accuracy: 0.7072 - val_loss: 0.5306\n",
      "Epoch 43/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391us/step - accuracy: 0.7501 - loss: 0.5060 - val_accuracy: 0.7492 - val_loss: 0.4686\n",
      "Epoch 44/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391us/step - accuracy: 0.7507 - loss: 0.5028 - val_accuracy: 0.7369 - val_loss: 0.4869\n",
      "Epoch 45/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391us/step - accuracy: 0.7525 - loss: 0.5023 - val_accuracy: 0.7072 - val_loss: 0.5292\n",
      "Epoch 46/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 395us/step - accuracy: 0.7517 - loss: 0.5032 - val_accuracy: 0.7249 - val_loss: 0.5075\n",
      "Epoch 47/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 399us/step - accuracy: 0.7465 - loss: 0.5064 - val_accuracy: 0.7185 - val_loss: 0.5158\n",
      "Epoch 48/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391us/step - accuracy: 0.7515 - loss: 0.5039 - val_accuracy: 0.7001 - val_loss: 0.5437\n",
      "Epoch 49/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391us/step - accuracy: 0.7472 - loss: 0.5085 - val_accuracy: 0.7676 - val_loss: 0.4488\n",
      "Epoch 50/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396us/step - accuracy: 0.7550 - loss: 0.5006 - val_accuracy: 0.7004 - val_loss: 0.5419\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_resampled, y_resampled, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=50, \n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1586/1586\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181us/step\n",
      "Test Accuracy: 0.7004\n",
      "Confusion Matrix:\n",
      "[[ 5813  1184]\n",
      " [14019 29720]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.83      0.43      6997\n",
      "           0       0.96      0.68      0.80     43739\n",
      "\n",
      "    accuracy                           0.70     50736\n",
      "   macro avg       0.63      0.76      0.61     50736\n",
      "weighted avg       0.87      0.70      0.75     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "testing_predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate accuracy\n",
    "test_accuracy = accuracy_score(y_test, testing_predictions)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, testing_predictions, labels=[1, 0])\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_test, testing_predictions, labels=[1, 0])\n",
    "print(f'Classification Report:\\n{class_report}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
