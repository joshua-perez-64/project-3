{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253676</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253677</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253678</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253679</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253680 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0                   0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1                   0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2                   0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3                   0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4                   0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "...                 ...     ...       ...        ...   ...     ...     ...   \n",
       "253675              0.0     1.0       1.0        1.0  45.0     0.0     0.0   \n",
       "253676              1.0     1.0       1.0        1.0  18.0     0.0     0.0   \n",
       "253677              0.0     0.0       0.0        1.0  28.0     0.0     0.0   \n",
       "253678              0.0     1.0       0.0        1.0  23.0     0.0     0.0   \n",
       "253679              1.0     1.0       1.0        1.0  25.0     0.0     0.0   \n",
       "\n",
       "        HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  \\\n",
       "0                        0.0           0.0     0.0      1.0   \n",
       "1                        0.0           1.0     0.0      0.0   \n",
       "2                        0.0           0.0     1.0      0.0   \n",
       "3                        0.0           1.0     1.0      1.0   \n",
       "4                        0.0           1.0     1.0      1.0   \n",
       "...                      ...           ...     ...      ...   \n",
       "253675                   0.0           0.0     1.0      1.0   \n",
       "253676                   0.0           0.0     0.0      0.0   \n",
       "253677                   0.0           1.0     1.0      0.0   \n",
       "253678                   0.0           0.0     1.0      1.0   \n",
       "253679                   1.0           1.0     1.0      0.0   \n",
       "\n",
       "        HvyAlcoholConsump  AnyHealthcare  NoDocbcCost  GenHlth  MentHlth  \\\n",
       "0                     0.0            1.0          0.0      5.0      18.0   \n",
       "1                     0.0            0.0          1.0      3.0       0.0   \n",
       "2                     0.0            1.0          1.0      5.0      30.0   \n",
       "3                     0.0            1.0          0.0      2.0       0.0   \n",
       "4                     0.0            1.0          0.0      2.0       3.0   \n",
       "...                   ...            ...          ...      ...       ...   \n",
       "253675                0.0            1.0          0.0      3.0       0.0   \n",
       "253676                0.0            1.0          0.0      4.0       0.0   \n",
       "253677                0.0            1.0          0.0      1.0       0.0   \n",
       "253678                0.0            1.0          0.0      3.0       0.0   \n",
       "253679                0.0            1.0          0.0      2.0       0.0   \n",
       "\n",
       "        PhysHlth  DiffWalk  Sex   Age  Education  Income  \n",
       "0           15.0       1.0  0.0   9.0        4.0     3.0  \n",
       "1            0.0       0.0  0.0   7.0        6.0     1.0  \n",
       "2           30.0       1.0  0.0   9.0        4.0     8.0  \n",
       "3            0.0       0.0  0.0  11.0        3.0     6.0  \n",
       "4            0.0       0.0  0.0  11.0        5.0     4.0  \n",
       "...          ...       ...  ...   ...        ...     ...  \n",
       "253675       5.0       0.0  1.0   5.0        6.0     7.0  \n",
       "253676       0.0       1.0  0.0  11.0        2.0     4.0  \n",
       "253677       0.0       0.0  0.0   2.0        5.0     2.0  \n",
       "253678       0.0       0.0  1.0   7.0        5.0     1.0  \n",
       "253679       0.0       0.0  0.0   9.0        6.0     2.0  \n",
       "\n",
       "[253680 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import dependencies and read in data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as ps\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import display\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "import pydotplus\n",
    "import os\n",
    "from IPython.display import Image\n",
    "from transformers import pipeline\n",
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "df = pd.read_csv(\"resources/diabetes_df.csv\")\n",
    "pd.options.display.max_columns = None\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253680 entries, 0 to 253679\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Diabetes_binary       253680 non-null  float64\n",
      " 1   HighBP                253680 non-null  float64\n",
      " 2   HighChol              253680 non-null  float64\n",
      " 3   CholCheck             253680 non-null  float64\n",
      " 4   BMI                   253680 non-null  float64\n",
      " 5   Smoker                253680 non-null  float64\n",
      " 6   Stroke                253680 non-null  float64\n",
      " 7   HeartDiseaseorAttack  253680 non-null  float64\n",
      " 8   PhysActivity          253680 non-null  float64\n",
      " 9   Fruits                253680 non-null  float64\n",
      " 10  Veggies               253680 non-null  float64\n",
      " 11  HvyAlcoholConsump     253680 non-null  float64\n",
      " 12  AnyHealthcare         253680 non-null  float64\n",
      " 13  NoDocbcCost           253680 non-null  float64\n",
      " 14  GenHlth               253680 non-null  float64\n",
      " 15  MentHlth              253680 non-null  float64\n",
      " 16  PhysHlth              253680 non-null  float64\n",
      " 17  DiffWalk              253680 non-null  float64\n",
      " 18  Sex                   253680 non-null  float64\n",
      " 19  Age                   253680 non-null  float64\n",
      " 20  Education             253680 non-null  float64\n",
      " 21  Income                253680 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 42.6 MB\n"
     ]
    }
   ],
   "source": [
    "#checking Dtypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0              0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1              0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2              0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3              0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4              0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  HvyAlcoholConsump  \\\n",
       "0                   0.0           0.0     0.0      1.0                0.0   \n",
       "1                   0.0           1.0     0.0      0.0                0.0   \n",
       "2                   0.0           0.0     1.0      0.0                0.0   \n",
       "3                   0.0           1.0     1.0      1.0                0.0   \n",
       "4                   0.0           1.0     1.0      1.0                0.0   \n",
       "\n",
       "   AnyHealthcare  NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex  \\\n",
       "0            1.0          0.0      5.0      18.0      15.0       1.0  0.0   \n",
       "1            0.0          1.0      3.0       0.0       0.0       0.0  0.0   \n",
       "2            1.0          1.0      5.0      30.0      30.0       1.0  0.0   \n",
       "3            1.0          0.0      2.0       0.0       0.0       0.0  0.0   \n",
       "4            1.0          0.0      2.0       3.0       0.0       0.0  0.0   \n",
       "\n",
       "    Age  Education  Income  \n",
       "0   9.0        4.0     3.0  \n",
       "1   7.0        6.0     1.0  \n",
       "2   9.0        4.0     8.0  \n",
       "3  11.0        3.0     6.0  \n",
       "4  11.0        5.0     4.0  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0              0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1              0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2              0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3              0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4              0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  HvyAlcoholConsump  \\\n",
       "0                   0.0           0.0     0.0      1.0                0.0   \n",
       "1                   0.0           1.0     0.0      0.0                0.0   \n",
       "2                   0.0           0.0     1.0      0.0                0.0   \n",
       "3                   0.0           1.0     1.0      1.0                0.0   \n",
       "4                   0.0           1.0     1.0      1.0                0.0   \n",
       "\n",
       "   GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \n",
       "0      5.0      18.0      15.0       1.0  0.0   9.0        4.0  \n",
       "1      3.0       0.0       0.0       0.0  0.0   7.0        6.0  \n",
       "2      5.0      30.0      30.0       1.0  0.0   9.0        4.0  \n",
       "3      2.0       0.0       0.0       0.0  0.0  11.0        3.0  \n",
       "4      2.0       3.0       0.0       0.0  0.0  11.0        5.0  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort dataframe for diabetes_binary, highbp, highchol, cholcheck, bmi, smoker, stroke, heart deseaseor attack, physactivity, fruits, veggies, hvyalcoholcunsump, genhealth, menthealth, physhealth, diffwalk, sex, education\n",
    "diabetes_df = df[['Diabetes_binary', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education']]\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_binary\n",
       "0.0    218334\n",
       "1.0     35346\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0= no\n",
    "#1= yes\n",
    "diabetes_df['Diabetes_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Histogram of Age\n",
    "sns.boxplot(diabetes_df['Age'])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_binary         0\n",
       "HighBP                  0\n",
       "HighChol                0\n",
       "CholCheck               0\n",
       "BMI                     0\n",
       "Smoker                  0\n",
       "Stroke                  0\n",
       "HeartDiseaseorAttack    0\n",
       "PhysActivity            0\n",
       "Fruits                  0\n",
       "Veggies                 0\n",
       "HvyAlcoholConsump       0\n",
       "GenHlth                 0\n",
       "MentHlth                0\n",
       "PhysHlth                0\n",
       "DiffWalk                0\n",
       "Sex                     0\n",
       "Age                     0\n",
       "Education               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count null values\n",
    "diabetes_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tz/nqby0pvn6llfbd7c3rtk0k280000gn/T/ipykernel_66003/4193381810.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diabetes_df['BMI'] = pd.DataFrame(scaler.fit_transform(diabetes_df[['BMI']]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253676</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253677</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253678</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253679</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253680 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Diabetes_binary  HighBP  HighChol  CholCheck       BMI  Smoker  \\\n",
       "0                   0.0     1.0       1.0        1.0  1.857143     1.0   \n",
       "1                   0.0     0.0       0.0        0.0 -0.285714     1.0   \n",
       "2                   0.0     1.0       1.0        1.0  0.142857     0.0   \n",
       "3                   0.0     1.0       0.0        1.0  0.000000     0.0   \n",
       "4                   0.0     1.0       1.0        1.0 -0.428571     0.0   \n",
       "...                 ...     ...       ...        ...       ...     ...   \n",
       "253675              0.0     1.0       1.0        1.0  2.571429     0.0   \n",
       "253676              1.0     1.0       1.0        1.0 -1.285714     0.0   \n",
       "253677              0.0     0.0       0.0        1.0  0.142857     0.0   \n",
       "253678              0.0     1.0       0.0        1.0 -0.571429     0.0   \n",
       "253679              1.0     1.0       1.0        1.0 -0.285714     0.0   \n",
       "\n",
       "        Stroke  HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  \\\n",
       "0          0.0                   0.0           0.0     0.0      1.0   \n",
       "1          0.0                   0.0           1.0     0.0      0.0   \n",
       "2          0.0                   0.0           0.0     1.0      0.0   \n",
       "3          0.0                   0.0           1.0     1.0      1.0   \n",
       "4          0.0                   0.0           1.0     1.0      1.0   \n",
       "...        ...                   ...           ...     ...      ...   \n",
       "253675     0.0                   0.0           0.0     1.0      1.0   \n",
       "253676     0.0                   0.0           0.0     0.0      0.0   \n",
       "253677     0.0                   0.0           1.0     1.0      0.0   \n",
       "253678     0.0                   0.0           0.0     1.0      1.0   \n",
       "253679     0.0                   1.0           1.0     1.0      0.0   \n",
       "\n",
       "        HvyAlcoholConsump  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  \\\n",
       "0                     0.0      5.0      18.0      15.0       1.0  0.0   9.0   \n",
       "1                     0.0      3.0       0.0       0.0       0.0  0.0   7.0   \n",
       "2                     0.0      5.0      30.0      30.0       1.0  0.0   9.0   \n",
       "3                     0.0      2.0       0.0       0.0       0.0  0.0  11.0   \n",
       "4                     0.0      2.0       3.0       0.0       0.0  0.0  11.0   \n",
       "...                   ...      ...       ...       ...       ...  ...   ...   \n",
       "253675                0.0      3.0       0.0       5.0       0.0  1.0   5.0   \n",
       "253676                0.0      4.0       0.0       0.0       1.0  0.0  11.0   \n",
       "253677                0.0      1.0       0.0       0.0       0.0  0.0   2.0   \n",
       "253678                0.0      3.0       0.0       0.0       0.0  1.0   7.0   \n",
       "253679                0.0      2.0       0.0       0.0       0.0  0.0   9.0   \n",
       "\n",
       "        Education  \n",
       "0             4.0  \n",
       "1             6.0  \n",
       "2             4.0  \n",
       "3             3.0  \n",
       "4             5.0  \n",
       "...           ...  \n",
       "253675        6.0  \n",
       "253676        2.0  \n",
       "253677        5.0  \n",
       "253678        5.0  \n",
       "253679        6.0  \n",
       "\n",
       "[253680 rows x 19 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = RobustScaler()\n",
    "diabetes_df['BMI'] = pd.DataFrame(scaler.fit_transform(diabetes_df[['BMI']]))\n",
    "diabetes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing sets\n",
    "# Create the features DataFrame, X\n",
    "X = diabetes_df.copy()\n",
    "X = X.drop(columns='Diabetes_binary')\n",
    "\n",
    "# Create the target DataFrame, y\n",
    "y = diabetes_df['Diabetes_binary']\n",
    "\n",
    "# Use train_test_split to separate the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an undersampler\n",
    "rus = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the data to create a balanced dataset\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled class distribution: Counter({0.0: 26489, 1.0: 26489})\n"
     ]
    }
   ],
   "source": [
    "# Check the class distribution after undersampling\n",
    "print(f\"Resampled class distribution: {Counter(y_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a `LogisticRegression` function and assign it \n",
    "# to a variable named `logistic_regression_model`.\n",
    "logistic_regression_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "logistic_regression_model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7267423525701672"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the fitted model to the `test` dataset\n",
    "testing_predictions = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Save both the test predictions and actual test values to a DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    \"Testing Data Predictions\": testing_predictions, \n",
    "    \"Testing Data Actual Targets\": y_test})\n",
    "\n",
    "# Calculate the model's accuracy on the test dataset\n",
    "accuracy_score(y_test, testing_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7267423525701672"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the fitted model to the `test` dataset\n",
    "testing_predictions = logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Save both the test predictions and actual test values to a DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    \"Testing Data Predictions\": testing_predictions, \n",
    "    \"Testing Data Actual Targets\": y_test})\n",
    "\n",
    "# Calculate the model's accuracy on the test dataset\n",
    "accuracy_score(y_test, testing_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6834  2023]\n",
      " [15307 39256]]\n"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "print(confusion_matrix(y_test,testing_predictions, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.77      0.44      8857\n",
      "           0       0.95      0.72      0.82     54563\n",
      "\n",
      "    accuracy                           0.73     63420\n",
      "   macro avg       0.63      0.75      0.63     63420\n",
      "weighted avg       0.86      0.73      0.77     63420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a classification report\n",
    "print(classification_report(y_test, testing_predictions, labels = [1, 0]))\n",
    "#logistics regression utilizing robust scaler on BMI higher recall focuses on finding false negitives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled class distribution: Counter({0.0: 28349, 1.0: 28349})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tz/nqby0pvn6llfbd7c3rtk0k280000gn/T/ipykernel_66003/1452167375.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diabetes_df['BMI'] = scaler.fit_transform(diabetes_df[['BMI']])\n"
     ]
    }
   ],
   "source": [
    "#ATTEMPT TO CODE NUERAL NETWORK\n",
    "\n",
    "# Scale BMI\n",
    "scaler = RobustScaler()\n",
    "diabetes_df['BMI'] = scaler.fit_transform(diabetes_df[['BMI']])\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = diabetes_df.drop(columns='Diabetes_binary')\n",
    "y = diabetes_df['Diabetes_binary']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Undersample to create a balanced dataset\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class distribution after undersampling\n",
    "print(f\"Resampled class distribution: {Counter(y_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer and first hidden layer with 16 neurons\n",
    "model.add(Dense(16, input_shape=(X_resampled.shape[1],), activation='relu'))\n",
    "\n",
    "# Add another hidden layer\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Output layer (since this is binary classification, use sigmoid activation)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438us/step - accuracy: 0.6864 - loss: 0.6030 - val_accuracy: 0.7199 - val_loss: 0.5216\n",
      "Epoch 2/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 406us/step - accuracy: 0.7400 - loss: 0.5214 - val_accuracy: 0.7507 - val_loss: 0.4770\n",
      "Epoch 3/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407us/step - accuracy: 0.7448 - loss: 0.5157 - val_accuracy: 0.7062 - val_loss: 0.5472\n",
      "Epoch 4/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420us/step - accuracy: 0.7449 - loss: 0.5160 - val_accuracy: 0.7344 - val_loss: 0.4981\n",
      "Epoch 5/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413us/step - accuracy: 0.7472 - loss: 0.5131 - val_accuracy: 0.6900 - val_loss: 0.5615\n",
      "Epoch 6/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 421us/step - accuracy: 0.7458 - loss: 0.5148 - val_accuracy: 0.7354 - val_loss: 0.4999\n",
      "Epoch 7/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413us/step - accuracy: 0.7483 - loss: 0.5111 - val_accuracy: 0.6911 - val_loss: 0.5646\n",
      "Epoch 8/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 408us/step - accuracy: 0.7451 - loss: 0.5145 - val_accuracy: 0.7373 - val_loss: 0.4925\n",
      "Epoch 9/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 406us/step - accuracy: 0.7471 - loss: 0.5100 - val_accuracy: 0.7413 - val_loss: 0.4911\n",
      "Epoch 10/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411us/step - accuracy: 0.7479 - loss: 0.5116 - val_accuracy: 0.7107 - val_loss: 0.5282\n",
      "Epoch 11/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413us/step - accuracy: 0.7481 - loss: 0.5111 - val_accuracy: 0.7093 - val_loss: 0.5281\n",
      "Epoch 12/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410us/step - accuracy: 0.7443 - loss: 0.5122 - val_accuracy: 0.7472 - val_loss: 0.4839\n",
      "Epoch 13/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423us/step - accuracy: 0.7437 - loss: 0.5106 - val_accuracy: 0.7277 - val_loss: 0.5135\n",
      "Epoch 14/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 412us/step - accuracy: 0.7460 - loss: 0.5097 - val_accuracy: 0.6986 - val_loss: 0.5505\n",
      "Epoch 15/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445us/step - accuracy: 0.7459 - loss: 0.5124 - val_accuracy: 0.7052 - val_loss: 0.5380\n",
      "Epoch 16/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - accuracy: 0.7483 - loss: 0.5073 - val_accuracy: 0.6899 - val_loss: 0.5593\n",
      "Epoch 17/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443us/step - accuracy: 0.7475 - loss: 0.5107 - val_accuracy: 0.7139 - val_loss: 0.5225\n",
      "Epoch 18/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490us/step - accuracy: 0.7439 - loss: 0.5117 - val_accuracy: 0.7198 - val_loss: 0.5249\n",
      "Epoch 19/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462us/step - accuracy: 0.7477 - loss: 0.5072 - val_accuracy: 0.7184 - val_loss: 0.5141\n",
      "Epoch 20/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509us/step - accuracy: 0.7463 - loss: 0.5113 - val_accuracy: 0.6966 - val_loss: 0.5493\n",
      "Epoch 21/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437us/step - accuracy: 0.7464 - loss: 0.5124 - val_accuracy: 0.7480 - val_loss: 0.4753\n",
      "Epoch 22/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439us/step - accuracy: 0.7475 - loss: 0.5084 - val_accuracy: 0.6552 - val_loss: 0.6112\n",
      "Epoch 23/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 479us/step - accuracy: 0.7494 - loss: 0.5064 - val_accuracy: 0.7106 - val_loss: 0.5295\n",
      "Epoch 24/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429us/step - accuracy: 0.7466 - loss: 0.5094 - val_accuracy: 0.7575 - val_loss: 0.4577\n",
      "Epoch 25/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438us/step - accuracy: 0.7475 - loss: 0.5105 - val_accuracy: 0.7062 - val_loss: 0.5353\n",
      "Epoch 26/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417us/step - accuracy: 0.7492 - loss: 0.5082 - val_accuracy: 0.7177 - val_loss: 0.5177\n",
      "Epoch 27/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450us/step - accuracy: 0.7462 - loss: 0.5089 - val_accuracy: 0.7075 - val_loss: 0.5423\n",
      "Epoch 28/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417us/step - accuracy: 0.7516 - loss: 0.5063 - val_accuracy: 0.7242 - val_loss: 0.5156\n",
      "Epoch 29/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420us/step - accuracy: 0.7491 - loss: 0.5070 - val_accuracy: 0.7487 - val_loss: 0.4768\n",
      "Epoch 30/30\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433us/step - accuracy: 0.7443 - loss: 0.5116 - val_accuracy: 0.7369 - val_loss: 0.4910\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_resampled, y_resampled, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=30, \n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1586/1586\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205us/step\n",
      "Test Accuracy: 0.7369\n",
      "Confusion Matrix:\n",
      "[[ 5454  1543]\n",
      " [11807 31932]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.78      0.45      6997\n",
      "           0       0.95      0.73      0.83     43739\n",
      "\n",
      "    accuracy                           0.74     50736\n",
      "   macro avg       0.63      0.75      0.64     50736\n",
      "weighted avg       0.87      0.74      0.78     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "testing_predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate accuracy\n",
    "test_accuracy = accuracy_score(y_test, testing_predictions)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, testing_predictions, labels=[1, 0])\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_test, testing_predictions, labels=[1, 0])\n",
    "print(f'Classification Report:\\n{class_report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Stroke  \\\n",
       "0              0.0     1.0       1.0        1.0  40.0     0.0   \n",
       "1              0.0     0.0       0.0        0.0  25.0     0.0   \n",
       "2              0.0     1.0       1.0        1.0  28.0     0.0   \n",
       "3              0.0     1.0       0.0        1.0  27.0     0.0   \n",
       "4              0.0     1.0       1.0        1.0  24.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  DiffWalk  Sex   Age  \n",
       "0                   0.0           0.0       1.0  0.0   9.0  \n",
       "1                   0.0           1.0       0.0  0.0   7.0  \n",
       "2                   0.0           0.0       1.0  0.0   9.0  \n",
       "3                   0.0           1.0       0.0  0.0  11.0  \n",
       "4                   0.0           1.0       0.0  0.0  11.0  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort dataframe for diabetes_binary, highbp, highchol, cholcheck, bmi, smoker, stroke, heart deseaseor attack, physactivity, fruits, veggies, hvyalcoholcunsump, genhealth, menthealth, physhealth, diffwalk, sex, education\n",
    "diabetes_df_dr_selected = df[['Diabetes_binary','HighBP', 'HighChol', 'CholCheck', 'BMI', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'DiffWalk', 'Sex', 'Age']]\n",
    "diabetes_df_dr_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled class distribution: Counter({0.0: 28349, 1.0: 28349})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tz/nqby0pvn6llfbd7c3rtk0k280000gn/T/ipykernel_66003/1246949071.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diabetes_df['BMI'] = scaler.fit_transform(diabetes_df[['BMI']])\n"
     ]
    }
   ],
   "source": [
    "#ATTEMPT TO CODE NUERAL NETWORK SELECTED CODE\n",
    "\n",
    "# Scale BMI\n",
    "scaler = RobustScaler()\n",
    "diabetes_df['BMI'] = scaler.fit_transform(diabetes_df[['BMI']])\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = diabetes_df_dr_selected.drop(columns='Diabetes_binary')\n",
    "y = diabetes_df_dr_selected['Diabetes_binary']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Undersample to create a balanced dataset\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class distribution after undersampling\n",
    "print(f\"Resampled class distribution: {Counter(y_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer and first hidden layer with 16 neurons\n",
    "model.add(Dense(16, input_shape=(X_resampled.shape[1],), activation='relu'))\n",
    "\n",
    "# Add another hidden layer\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Output layer (since this is binary classification, use sigmoid activation)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461us/step - accuracy: 0.6338 - loss: 0.6369 - val_accuracy: 0.6814 - val_loss: 0.6106\n",
      "Epoch 2/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440us/step - accuracy: 0.7152 - loss: 0.5607 - val_accuracy: 0.6964 - val_loss: 0.5830\n",
      "Epoch 3/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428us/step - accuracy: 0.7208 - loss: 0.5539 - val_accuracy: 0.6479 - val_loss: 0.6602\n",
      "Epoch 4/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429us/step - accuracy: 0.7237 - loss: 0.5497 - val_accuracy: 0.6641 - val_loss: 0.6331\n",
      "Epoch 5/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429us/step - accuracy: 0.7266 - loss: 0.5472 - val_accuracy: 0.6659 - val_loss: 0.6271\n",
      "Epoch 6/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427us/step - accuracy: 0.7251 - loss: 0.5484 - val_accuracy: 0.6556 - val_loss: 0.6463\n",
      "Epoch 7/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438us/step - accuracy: 0.7250 - loss: 0.5471 - val_accuracy: 0.7082 - val_loss: 0.5596\n",
      "Epoch 8/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424us/step - accuracy: 0.7271 - loss: 0.5442 - val_accuracy: 0.6957 - val_loss: 0.5758\n",
      "Epoch 9/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 432us/step - accuracy: 0.7267 - loss: 0.5434 - val_accuracy: 0.6830 - val_loss: 0.5939\n",
      "Epoch 10/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427us/step - accuracy: 0.7255 - loss: 0.5428 - val_accuracy: 0.7442 - val_loss: 0.5003\n",
      "Epoch 11/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430us/step - accuracy: 0.7280 - loss: 0.5423 - val_accuracy: 0.7114 - val_loss: 0.5411\n",
      "Epoch 12/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449us/step - accuracy: 0.7298 - loss: 0.5395 - val_accuracy: 0.7485 - val_loss: 0.4940\n",
      "Epoch 13/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 456us/step - accuracy: 0.7253 - loss: 0.5425 - val_accuracy: 0.7210 - val_loss: 0.5259\n",
      "Epoch 14/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428us/step - accuracy: 0.7264 - loss: 0.5434 - val_accuracy: 0.6734 - val_loss: 0.5893\n",
      "Epoch 15/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420us/step - accuracy: 0.7272 - loss: 0.5423 - val_accuracy: 0.7202 - val_loss: 0.5262\n",
      "Epoch 16/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420us/step - accuracy: 0.7266 - loss: 0.5430 - val_accuracy: 0.6935 - val_loss: 0.5632\n",
      "Epoch 17/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439us/step - accuracy: 0.7311 - loss: 0.5376 - val_accuracy: 0.6593 - val_loss: 0.6129\n",
      "Epoch 18/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430us/step - accuracy: 0.7282 - loss: 0.5422 - val_accuracy: 0.7073 - val_loss: 0.5412\n",
      "Epoch 19/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430us/step - accuracy: 0.7304 - loss: 0.5377 - val_accuracy: 0.7084 - val_loss: 0.5424\n",
      "Epoch 20/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429us/step - accuracy: 0.7282 - loss: 0.5417 - val_accuracy: 0.6899 - val_loss: 0.5651\n",
      "Epoch 21/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425us/step - accuracy: 0.7259 - loss: 0.5428 - val_accuracy: 0.6708 - val_loss: 0.5903\n",
      "Epoch 22/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434us/step - accuracy: 0.7301 - loss: 0.5385 - val_accuracy: 0.6995 - val_loss: 0.5446\n",
      "Epoch 23/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417us/step - accuracy: 0.7268 - loss: 0.5379 - val_accuracy: 0.7011 - val_loss: 0.5377\n",
      "Epoch 24/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417us/step - accuracy: 0.7317 - loss: 0.5367 - val_accuracy: 0.6734 - val_loss: 0.5892\n",
      "Epoch 25/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415us/step - accuracy: 0.7275 - loss: 0.5396 - val_accuracy: 0.7157 - val_loss: 0.5300\n",
      "Epoch 26/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422us/step - accuracy: 0.7274 - loss: 0.5421 - val_accuracy: 0.6867 - val_loss: 0.5762\n",
      "Epoch 27/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434us/step - accuracy: 0.7280 - loss: 0.5374 - val_accuracy: 0.6757 - val_loss: 0.5790\n",
      "Epoch 28/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427us/step - accuracy: 0.7262 - loss: 0.5401 - val_accuracy: 0.6992 - val_loss: 0.5477\n",
      "Epoch 29/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420us/step - accuracy: 0.7281 - loss: 0.5393 - val_accuracy: 0.6877 - val_loss: 0.5549\n",
      "Epoch 30/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417us/step - accuracy: 0.7301 - loss: 0.5402 - val_accuracy: 0.7362 - val_loss: 0.4845\n",
      "Epoch 31/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420us/step - accuracy: 0.7270 - loss: 0.5394 - val_accuracy: 0.6730 - val_loss: 0.5713\n",
      "Epoch 32/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434us/step - accuracy: 0.7306 - loss: 0.5363 - val_accuracy: 0.7070 - val_loss: 0.5251\n",
      "Epoch 33/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443us/step - accuracy: 0.7278 - loss: 0.5397 - val_accuracy: 0.6936 - val_loss: 0.5493\n",
      "Epoch 34/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429us/step - accuracy: 0.7270 - loss: 0.5387 - val_accuracy: 0.7254 - val_loss: 0.4986\n",
      "Epoch 35/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 421us/step - accuracy: 0.7263 - loss: 0.5395 - val_accuracy: 0.7188 - val_loss: 0.5094\n",
      "Epoch 36/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430us/step - accuracy: 0.7286 - loss: 0.5381 - val_accuracy: 0.6848 - val_loss: 0.5637\n",
      "Epoch 37/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 421us/step - accuracy: 0.7333 - loss: 0.5337 - val_accuracy: 0.6973 - val_loss: 0.5434\n",
      "Epoch 38/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420us/step - accuracy: 0.7310 - loss: 0.5369 - val_accuracy: 0.7658 - val_loss: 0.4459\n",
      "Epoch 39/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417us/step - accuracy: 0.7311 - loss: 0.5365 - val_accuracy: 0.6939 - val_loss: 0.5452\n",
      "Epoch 40/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438us/step - accuracy: 0.7280 - loss: 0.5363 - val_accuracy: 0.6936 - val_loss: 0.5503\n",
      "Epoch 41/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 421us/step - accuracy: 0.7310 - loss: 0.5362 - val_accuracy: 0.6894 - val_loss: 0.5589\n",
      "Epoch 42/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420us/step - accuracy: 0.7291 - loss: 0.5376 - val_accuracy: 0.7279 - val_loss: 0.4992\n",
      "Epoch 43/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 418us/step - accuracy: 0.7297 - loss: 0.5346 - val_accuracy: 0.6776 - val_loss: 0.5711\n",
      "Epoch 44/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435us/step - accuracy: 0.7300 - loss: 0.5348 - val_accuracy: 0.7044 - val_loss: 0.5301\n",
      "Epoch 45/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 458us/step - accuracy: 0.7295 - loss: 0.5387 - val_accuracy: 0.7293 - val_loss: 0.4993\n",
      "Epoch 46/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 421us/step - accuracy: 0.7301 - loss: 0.5357 - val_accuracy: 0.7211 - val_loss: 0.5137\n",
      "Epoch 47/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423us/step - accuracy: 0.7263 - loss: 0.5391 - val_accuracy: 0.7159 - val_loss: 0.5195\n",
      "Epoch 48/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420us/step - accuracy: 0.7293 - loss: 0.5359 - val_accuracy: 0.7039 - val_loss: 0.5358\n",
      "Epoch 49/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433us/step - accuracy: 0.7322 - loss: 0.5323 - val_accuracy: 0.6920 - val_loss: 0.5472\n",
      "Epoch 50/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433us/step - accuracy: 0.7311 - loss: 0.5324 - val_accuracy: 0.7050 - val_loss: 0.5318\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_resampled, y_resampled, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=50, \n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1586/1586\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202us/step\n",
      "Test Accuracy: 0.7050\n",
      "Confusion Matrix:\n",
      "[[ 5447  1550]\n",
      " [13416 30323]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.78      0.42      6997\n",
      "           0       0.95      0.69      0.80     43739\n",
      "\n",
      "    accuracy                           0.71     50736\n",
      "   macro avg       0.62      0.74      0.61     50736\n",
      "weighted avg       0.86      0.71      0.75     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "testing_predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate accuracy\n",
    "test_accuracy = accuracy_score(y_test, testing_predictions)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, testing_predictions, labels=[1, 0])\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_test, testing_predictions, labels=[1, 0])\n",
    "print(f'Classification Report:\\n{class_report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>BMI</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary   BMI  GenHlth  PhysHlth   Age\n",
       "0              0.0  40.0      5.0      15.0   9.0\n",
       "1              0.0  25.0      3.0       0.0   7.0\n",
       "2              0.0  28.0      5.0      30.0   9.0\n",
       "3              0.0  27.0      2.0       0.0  11.0\n",
       "4              0.0  24.0      2.0       0.0  11.0"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort dataframe for diabetes_binary, highbp, highchol, cholcheck, bmi, smoker, stroke, heart deseaseor attack, physactivity, fruits, veggies, hvyalcoholcunsump, genhealth, menthealth, physhealth, diffwalk, sex, education\n",
    "diabetes_df_ai_selected = df[['Diabetes_binary', 'BMI', 'GenHlth', 'PhysHlth', 'Age']]\n",
    "diabetes_df_ai_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled class distribution: Counter({0.0: 28349, 1.0: 28349})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tz/nqby0pvn6llfbd7c3rtk0k280000gn/T/ipykernel_66003/2154139418.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diabetes_df['BMI'] = scaler.fit_transform(diabetes_df[['BMI']])\n"
     ]
    }
   ],
   "source": [
    "#ATTEMPT TO CODE NUERAL NETWORK AI SELECTED CODE\n",
    "\n",
    "# Scale BMI\n",
    "scaler = RobustScaler()\n",
    "diabetes_df['BMI'] = scaler.fit_transform(diabetes_df[['BMI']])\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = diabetes_df_ai_selected.drop(columns='Diabetes_binary')\n",
    "y = diabetes_df_ai_selected['Diabetes_binary']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Undersample to create a balanced dataset\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class distribution after undersampling\n",
    "print(f\"Resampled class distribution: {Counter(y_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer and first hidden layer with 16 neurons\n",
    "model.add(Dense(16, input_shape=(X_resampled.shape[1],), activation='relu'))\n",
    "\n",
    "# Add another hidden layer\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Output layer (since this is binary classification, use sigmoid activation)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461us/step - accuracy: 0.6086 - loss: 0.8692 - val_accuracy: 0.7603 - val_loss: 0.5567\n",
      "Epoch 2/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431us/step - accuracy: 0.6939 - loss: 0.5951 - val_accuracy: 0.7232 - val_loss: 0.5556\n",
      "Epoch 3/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425us/step - accuracy: 0.7188 - loss: 0.5612 - val_accuracy: 0.7227 - val_loss: 0.5475\n",
      "Epoch 4/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437us/step - accuracy: 0.7210 - loss: 0.5518 - val_accuracy: 0.7322 - val_loss: 0.5382\n",
      "Epoch 5/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 465us/step - accuracy: 0.7219 - loss: 0.5498 - val_accuracy: 0.7723 - val_loss: 0.4746\n",
      "Epoch 6/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422us/step - accuracy: 0.7237 - loss: 0.5468 - val_accuracy: 0.7550 - val_loss: 0.5047\n",
      "Epoch 7/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420us/step - accuracy: 0.7251 - loss: 0.5455 - val_accuracy: 0.6604 - val_loss: 0.6401\n",
      "Epoch 8/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415us/step - accuracy: 0.7213 - loss: 0.5495 - val_accuracy: 0.7160 - val_loss: 0.5576\n",
      "Epoch 9/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419us/step - accuracy: 0.7231 - loss: 0.5473 - val_accuracy: 0.6310 - val_loss: 0.6874\n",
      "Epoch 10/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428us/step - accuracy: 0.7295 - loss: 0.5411 - val_accuracy: 0.7119 - val_loss: 0.5548\n",
      "Epoch 11/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440us/step - accuracy: 0.7271 - loss: 0.5434 - val_accuracy: 0.7447 - val_loss: 0.5090\n",
      "Epoch 12/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425us/step - accuracy: 0.7239 - loss: 0.5447 - val_accuracy: 0.7667 - val_loss: 0.4744\n",
      "Epoch 13/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415us/step - accuracy: 0.7274 - loss: 0.5435 - val_accuracy: 0.7716 - val_loss: 0.4711\n",
      "Epoch 14/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414us/step - accuracy: 0.7248 - loss: 0.5447 - val_accuracy: 0.7490 - val_loss: 0.5013\n",
      "Epoch 15/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - accuracy: 0.7266 - loss: 0.5397 - val_accuracy: 0.7258 - val_loss: 0.5350\n",
      "Epoch 16/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511us/step - accuracy: 0.7262 - loss: 0.5429 - val_accuracy: 0.7083 - val_loss: 0.5590\n",
      "Epoch 17/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417us/step - accuracy: 0.7273 - loss: 0.5441 - val_accuracy: 0.7041 - val_loss: 0.5706\n",
      "Epoch 18/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415us/step - accuracy: 0.7282 - loss: 0.5410 - val_accuracy: 0.7229 - val_loss: 0.5358\n",
      "Epoch 19/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428us/step - accuracy: 0.7257 - loss: 0.5443 - val_accuracy: 0.7274 - val_loss: 0.5305\n",
      "Epoch 20/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 433us/step - accuracy: 0.7255 - loss: 0.5445 - val_accuracy: 0.6760 - val_loss: 0.6060\n",
      "Epoch 21/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 461us/step - accuracy: 0.7276 - loss: 0.5412 - val_accuracy: 0.6972 - val_loss: 0.5767\n",
      "Epoch 22/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510us/step - accuracy: 0.7271 - loss: 0.5427 - val_accuracy: 0.6845 - val_loss: 0.5928\n",
      "Epoch 23/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 474us/step - accuracy: 0.7280 - loss: 0.5412 - val_accuracy: 0.6643 - val_loss: 0.6195\n",
      "Epoch 24/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442us/step - accuracy: 0.7250 - loss: 0.5440 - val_accuracy: 0.7114 - val_loss: 0.5516\n",
      "Epoch 25/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426us/step - accuracy: 0.7250 - loss: 0.5424 - val_accuracy: 0.7148 - val_loss: 0.5448\n",
      "Epoch 26/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444us/step - accuracy: 0.7279 - loss: 0.5402 - val_accuracy: 0.6966 - val_loss: 0.5714\n",
      "Epoch 27/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 479us/step - accuracy: 0.7259 - loss: 0.5413 - val_accuracy: 0.7539 - val_loss: 0.4873\n",
      "Epoch 28/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 478us/step - accuracy: 0.7278 - loss: 0.5429 - val_accuracy: 0.7178 - val_loss: 0.5405\n",
      "Epoch 29/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422us/step - accuracy: 0.7272 - loss: 0.5404 - val_accuracy: 0.7306 - val_loss: 0.5211\n",
      "Epoch 30/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413us/step - accuracy: 0.7270 - loss: 0.5400 - val_accuracy: 0.6965 - val_loss: 0.5685\n",
      "Epoch 31/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410us/step - accuracy: 0.7299 - loss: 0.5373 - val_accuracy: 0.7032 - val_loss: 0.5408\n",
      "Epoch 32/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415us/step - accuracy: 0.7296 - loss: 0.5359 - val_accuracy: 0.6720 - val_loss: 0.5777\n",
      "Epoch 33/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428us/step - accuracy: 0.7271 - loss: 0.5390 - val_accuracy: 0.7145 - val_loss: 0.5390\n",
      "Epoch 34/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413us/step - accuracy: 0.7277 - loss: 0.5378 - val_accuracy: 0.7335 - val_loss: 0.5173\n",
      "Epoch 35/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419us/step - accuracy: 0.7279 - loss: 0.5375 - val_accuracy: 0.7151 - val_loss: 0.5124\n",
      "Epoch 36/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417us/step - accuracy: 0.7276 - loss: 0.5386 - val_accuracy: 0.6837 - val_loss: 0.5736\n",
      "Epoch 37/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413us/step - accuracy: 0.7274 - loss: 0.5402 - val_accuracy: 0.6958 - val_loss: 0.5667\n",
      "Epoch 38/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 412us/step - accuracy: 0.7291 - loss: 0.5368 - val_accuracy: 0.6862 - val_loss: 0.5448\n",
      "Epoch 39/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 418us/step - accuracy: 0.7293 - loss: 0.5360 - val_accuracy: 0.7104 - val_loss: 0.5365\n",
      "Epoch 40/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414us/step - accuracy: 0.7268 - loss: 0.5380 - val_accuracy: 0.7181 - val_loss: 0.5254\n",
      "Epoch 41/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 412us/step - accuracy: 0.7277 - loss: 0.5401 - val_accuracy: 0.7218 - val_loss: 0.5252\n",
      "Epoch 42/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414us/step - accuracy: 0.7242 - loss: 0.5416 - val_accuracy: 0.6981 - val_loss: 0.5622\n",
      "Epoch 43/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413us/step - accuracy: 0.7291 - loss: 0.5388 - val_accuracy: 0.6371 - val_loss: 0.6312\n",
      "Epoch 44/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430us/step - accuracy: 0.7283 - loss: 0.5391 - val_accuracy: 0.6925 - val_loss: 0.5469\n",
      "Epoch 45/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422us/step - accuracy: 0.7281 - loss: 0.5381 - val_accuracy: 0.7058 - val_loss: 0.5431\n",
      "Epoch 46/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428us/step - accuracy: 0.7257 - loss: 0.5387 - val_accuracy: 0.6757 - val_loss: 0.5743\n",
      "Epoch 47/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 462us/step - accuracy: 0.7250 - loss: 0.5389 - val_accuracy: 0.7069 - val_loss: 0.5413\n",
      "Epoch 48/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416us/step - accuracy: 0.7277 - loss: 0.5369 - val_accuracy: 0.7244 - val_loss: 0.5024\n",
      "Epoch 49/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439us/step - accuracy: 0.7270 - loss: 0.5372 - val_accuracy: 0.7079 - val_loss: 0.5268\n",
      "Epoch 50/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step - accuracy: 0.7298 - loss: 0.5351 - val_accuracy: 0.7055 - val_loss: 0.5231\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_resampled, y_resampled, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=50, \n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1586/1586\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239us/step\n",
      "Test Accuracy: 0.7055\n",
      "Confusion Matrix:\n",
      "[[ 5385  1612]\n",
      " [13331 30408]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.77      0.42      6997\n",
      "           0       0.95      0.70      0.80     43739\n",
      "\n",
      "    accuracy                           0.71     50736\n",
      "   macro avg       0.62      0.73      0.61     50736\n",
      "weighted avg       0.86      0.71      0.75     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "testing_predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate accuracy\n",
    "test_accuracy = accuracy_score(y_test, testing_predictions)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, testing_predictions, labels=[1, 0])\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_test, testing_predictions, labels=[1, 0])\n",
    "print(f'Classification Report:\\n{class_report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0              0.0     1.0        1.0  40.0     1.0     0.0   \n",
       "1              0.0     0.0        0.0  25.0     1.0     0.0   \n",
       "2              0.0     1.0        1.0  28.0     0.0     0.0   \n",
       "3              0.0     1.0        1.0  27.0     0.0     0.0   \n",
       "4              0.0     1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  HvyAlcoholConsump  \\\n",
       "0                   0.0           0.0     0.0      1.0                0.0   \n",
       "1                   0.0           1.0     0.0      0.0                0.0   \n",
       "2                   0.0           0.0     1.0      0.0                0.0   \n",
       "3                   0.0           1.0     1.0      1.0                0.0   \n",
       "4                   0.0           1.0     1.0      1.0                0.0   \n",
       "\n",
       "   GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  Income  \\\n",
       "0      5.0      18.0      15.0       1.0  0.0   9.0        4.0     3.0   \n",
       "1      3.0       0.0       0.0       0.0  0.0   7.0        6.0     1.0   \n",
       "2      5.0      30.0      30.0       1.0  0.0   9.0        4.0     8.0   \n",
       "3      2.0       0.0       0.0       0.0  0.0  11.0        3.0     6.0   \n",
       "4      2.0       3.0       0.0       0.0  0.0  11.0        5.0     4.0   \n",
       "\n",
       "   AnyHealthcare  NoDocbcCost  \n",
       "0            1.0          0.0  \n",
       "1            0.0          1.0  \n",
       "2            1.0          1.0  \n",
       "3            1.0          0.0  \n",
       "4            1.0          0.0  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort dataframe for diabetes_binary, highbp, highchol, cholcheck, bmi, smoker, stroke, heart deseaseor attack, physactivity, fruits, veggies, hvyalcoholcunsump, genhealth, menthealth, physhealth, diffwalk, sex, education\n",
    "diabetes_df_chatbot_selected = df[['Diabetes_binary', 'HighBP', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income', 'AnyHealthcare']]\n",
    "diabetes_df_chatbot_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled class distribution: Counter({0.0: 28349, 1.0: 28349})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tz/nqby0pvn6llfbd7c3rtk0k280000gn/T/ipykernel_66003/364770516.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diabetes_df['BMI'] = scaler.fit_transform(diabetes_df[['BMI']])\n"
     ]
    }
   ],
   "source": [
    "#ATTEMPT TO CODE NUERAL NETWORK CHATBOT SELECTED CODE\n",
    "\n",
    "# Scale BMI\n",
    "scaler = RobustScaler()\n",
    "diabetes_df['BMI'] = scaler.fit_transform(diabetes_df[['BMI']])\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = diabetes_df_chatbot_selected.drop(columns='Diabetes_binary')\n",
    "y = diabetes_df_chatbot_selected['Diabetes_binary']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Undersample to create a balanced dataset\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class distribution after undersampling\n",
    "print(f\"Resampled class distribution: {Counter(y_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer and first hidden layer with 16 neurons\n",
    "model.add(Dense(16, input_shape=(X_resampled.shape[1],), activation='relu'))\n",
    "\n",
    "# Add another hidden layer\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Output layer (since this is binary classification, use sigmoid activation)\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 473us/step - accuracy: 0.6510 - loss: 0.6319 - val_accuracy: 0.7218 - val_loss: 0.5277\n",
      "Epoch 2/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411us/step - accuracy: 0.7268 - loss: 0.5393 - val_accuracy: 0.7068 - val_loss: 0.5405\n",
      "Epoch 3/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414us/step - accuracy: 0.7293 - loss: 0.5358 - val_accuracy: 0.7120 - val_loss: 0.5257\n",
      "Epoch 4/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417us/step - accuracy: 0.7359 - loss: 0.5263 - val_accuracy: 0.6985 - val_loss: 0.5424\n",
      "Epoch 5/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 418us/step - accuracy: 0.7336 - loss: 0.5277 - val_accuracy: 0.7143 - val_loss: 0.5167\n",
      "Epoch 6/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419us/step - accuracy: 0.7374 - loss: 0.5232 - val_accuracy: 0.6895 - val_loss: 0.5537\n",
      "Epoch 7/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442us/step - accuracy: 0.7383 - loss: 0.5224 - val_accuracy: 0.7351 - val_loss: 0.4919\n",
      "Epoch 8/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417us/step - accuracy: 0.7386 - loss: 0.5197 - val_accuracy: 0.6964 - val_loss: 0.5338\n",
      "Epoch 9/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416us/step - accuracy: 0.7400 - loss: 0.5215 - val_accuracy: 0.7274 - val_loss: 0.5019\n",
      "Epoch 10/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411us/step - accuracy: 0.7414 - loss: 0.5192 - val_accuracy: 0.6939 - val_loss: 0.5464\n",
      "Epoch 11/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410us/step - accuracy: 0.7439 - loss: 0.5177 - val_accuracy: 0.6819 - val_loss: 0.5731\n",
      "Epoch 12/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434us/step - accuracy: 0.7410 - loss: 0.5176 - val_accuracy: 0.7100 - val_loss: 0.5270\n",
      "Epoch 13/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419us/step - accuracy: 0.7425 - loss: 0.5163 - val_accuracy: 0.6641 - val_loss: 0.5959\n",
      "Epoch 14/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417us/step - accuracy: 0.7442 - loss: 0.5154 - val_accuracy: 0.6918 - val_loss: 0.5457\n",
      "Epoch 15/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414us/step - accuracy: 0.7417 - loss: 0.5174 - val_accuracy: 0.7118 - val_loss: 0.5208\n",
      "Epoch 16/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416us/step - accuracy: 0.7447 - loss: 0.5123 - val_accuracy: 0.6956 - val_loss: 0.5429\n",
      "Epoch 17/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419us/step - accuracy: 0.7468 - loss: 0.5127 - val_accuracy: 0.6813 - val_loss: 0.5681\n",
      "Epoch 18/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439us/step - accuracy: 0.7409 - loss: 0.5171 - val_accuracy: 0.7361 - val_loss: 0.4782\n",
      "Epoch 19/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 415us/step - accuracy: 0.7412 - loss: 0.5146 - val_accuracy: 0.6925 - val_loss: 0.5497\n",
      "Epoch 20/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 418us/step - accuracy: 0.7455 - loss: 0.5134 - val_accuracy: 0.7167 - val_loss: 0.5193\n",
      "Epoch 21/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 417us/step - accuracy: 0.7405 - loss: 0.5162 - val_accuracy: 0.7150 - val_loss: 0.5261\n",
      "Epoch 22/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422us/step - accuracy: 0.7448 - loss: 0.5135 - val_accuracy: 0.7354 - val_loss: 0.4930\n",
      "Epoch 23/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434us/step - accuracy: 0.7424 - loss: 0.5165 - val_accuracy: 0.6950 - val_loss: 0.5419\n",
      "Epoch 24/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 454us/step - accuracy: 0.7459 - loss: 0.5126 - val_accuracy: 0.7165 - val_loss: 0.5152\n",
      "Epoch 25/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 460us/step - accuracy: 0.7471 - loss: 0.5120 - val_accuracy: 0.7098 - val_loss: 0.5147\n",
      "Epoch 26/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441us/step - accuracy: 0.7419 - loss: 0.5157 - val_accuracy: 0.6978 - val_loss: 0.5386\n",
      "Epoch 27/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434us/step - accuracy: 0.7494 - loss: 0.5105 - val_accuracy: 0.7520 - val_loss: 0.4706\n",
      "Epoch 28/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411us/step - accuracy: 0.7425 - loss: 0.5154 - val_accuracy: 0.7421 - val_loss: 0.4812\n",
      "Epoch 29/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414us/step - accuracy: 0.7449 - loss: 0.5116 - val_accuracy: 0.6974 - val_loss: 0.5485\n",
      "Epoch 30/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428us/step - accuracy: 0.7439 - loss: 0.5113 - val_accuracy: 0.7544 - val_loss: 0.4563\n",
      "Epoch 31/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 421us/step - accuracy: 0.7452 - loss: 0.5110 - val_accuracy: 0.7110 - val_loss: 0.5281\n",
      "Epoch 32/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436us/step - accuracy: 0.7484 - loss: 0.5103 - val_accuracy: 0.7413 - val_loss: 0.4843\n",
      "Epoch 33/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416us/step - accuracy: 0.7456 - loss: 0.5135 - val_accuracy: 0.6796 - val_loss: 0.5921\n",
      "Epoch 34/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413us/step - accuracy: 0.7447 - loss: 0.5127 - val_accuracy: 0.6985 - val_loss: 0.5483\n",
      "Epoch 35/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 418us/step - accuracy: 0.7423 - loss: 0.5156 - val_accuracy: 0.7088 - val_loss: 0.5177\n",
      "Epoch 36/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416us/step - accuracy: 0.7441 - loss: 0.5096 - val_accuracy: 0.7308 - val_loss: 0.5073\n",
      "Epoch 37/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434us/step - accuracy: 0.7446 - loss: 0.5135 - val_accuracy: 0.6747 - val_loss: 0.5775\n",
      "Epoch 38/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416us/step - accuracy: 0.7436 - loss: 0.5129 - val_accuracy: 0.7290 - val_loss: 0.5081\n",
      "Epoch 39/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411us/step - accuracy: 0.7450 - loss: 0.5111 - val_accuracy: 0.7255 - val_loss: 0.5086\n",
      "Epoch 40/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413us/step - accuracy: 0.7470 - loss: 0.5106 - val_accuracy: 0.6809 - val_loss: 0.5701\n",
      "Epoch 41/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410us/step - accuracy: 0.7480 - loss: 0.5108 - val_accuracy: 0.7502 - val_loss: 0.4755\n",
      "Epoch 42/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426us/step - accuracy: 0.7431 - loss: 0.5123 - val_accuracy: 0.7308 - val_loss: 0.4927\n",
      "Epoch 43/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 407us/step - accuracy: 0.7445 - loss: 0.5126 - val_accuracy: 0.7113 - val_loss: 0.5318\n",
      "Epoch 44/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414us/step - accuracy: 0.7500 - loss: 0.5063 - val_accuracy: 0.7135 - val_loss: 0.5269\n",
      "Epoch 45/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413us/step - accuracy: 0.7433 - loss: 0.5112 - val_accuracy: 0.7306 - val_loss: 0.5024\n",
      "Epoch 46/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409us/step - accuracy: 0.7463 - loss: 0.5092 - val_accuracy: 0.7612 - val_loss: 0.4575\n",
      "Epoch 47/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 409us/step - accuracy: 0.7418 - loss: 0.5123 - val_accuracy: 0.7031 - val_loss: 0.5466\n",
      "Epoch 48/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423us/step - accuracy: 0.7468 - loss: 0.5101 - val_accuracy: 0.7267 - val_loss: 0.5064\n",
      "Epoch 49/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 412us/step - accuracy: 0.7452 - loss: 0.5103 - val_accuracy: 0.7515 - val_loss: 0.4701\n",
      "Epoch 50/50\n",
      "\u001b[1m1772/1772\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429us/step - accuracy: 0.7466 - loss: 0.5134 - val_accuracy: 0.6973 - val_loss: 0.5531\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_resampled, y_resampled, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=50, \n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1586/1586\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195us/step\n",
      "Test Accuracy: 0.6973\n",
      "Confusion Matrix:\n",
      "[[ 5780  1217]\n",
      " [14139 29600]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.83      0.43      6997\n",
      "           0       0.96      0.68      0.79     43739\n",
      "\n",
      "    accuracy                           0.70     50736\n",
      "   macro avg       0.63      0.75      0.61     50736\n",
      "weighted avg       0.87      0.70      0.74     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "testing_predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Calculate accuracy\n",
    "test_accuracy = accuracy_score(y_test, testing_predictions)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, testing_predictions, labels=[1, 0])\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(y_test, testing_predictions, labels=[1, 0])\n",
    "print(f'Classification Report:\\n{class_report}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
